# File Handling and I/O Operations in Python

## Table of Contents
1. [File Operations](#file-operations)
2. [File Modes and Encoding](#file-modes-and-encoding)
3. [Context Managers](#context-managers)
4. [Binary Files](#binary-files)
5. [CSV and JSON](#csv-and-json)
6. [Serialization](#serialization)
7. [Path Operations](#path-operations)
8. [Advanced I/O](#advanced-io)

## File Operations

### Basic File Operations

```python
from typing import List, Optional
import os

def read_file(filepath: str, encoding: str = 'utf-8') -> str:
    """
    Read entire file content.
    
    Args:
        filepath: Path to file
        encoding: File encoding
        
    Returns:
        str: File content
        
    Raises:
        FileNotFoundError: If file doesn't exist
    """
    with open(filepath, 'r', encoding=encoding) as f:
        return f.read()

def write_file(
    filepath: str,
    content: str,
    encoding: str = 'utf-8'
) -> None:
    """
    Write content to file.
    
    Args:
        filepath: Path to file
        content: Content to write
        encoding: File encoding
    """
    with open(filepath, 'w', encoding=encoding) as f:
        f.write(content)

def append_to_file(
    filepath: str,
    content: str,
    encoding: str = 'utf-8'
) -> None:
    """
    Append content to file.
    
    Args:
        filepath: Path to file
        content: Content to append
        encoding: File encoding
    """
    with open(filepath, 'a', encoding=encoding) as f:
        f.write(content)
```

### Line Operations

```python
def read_lines(
    filepath: str,
    strip: bool = True,
    encoding: str = 'utf-8'
) -> List[str]:
    """
    Read file lines into list.
    
    Args:
        filepath: Path to file
        strip: Whether to strip whitespace
        encoding: File encoding
        
    Returns:
        List[str]: List of lines
    """
    with open(filepath, 'r', encoding=encoding) as f:
        if strip:
            return [line.strip() for line in f]
        return list(f)

def write_lines(
    filepath: str,
    lines: List[str],
    encoding: str = 'utf-8'
) -> None:
    """
    Write lines to file.
    
    Args:
        filepath: Path to file
        lines: Lines to write
        encoding: File encoding
    """
    with open(filepath, 'w', encoding=encoding) as f:
        f.writelines(f"{line}\n" for line in lines)
```

## File Modes and Encoding

### File Mode Examples

```python
def demonstrate_file_modes() -> None:
    """Demonstrate different file modes."""
    
    # Write mode ('w'): Creates new file, truncates if exists
    with open('example.txt', 'w') as f:
        f.write('Hello, World!')
    
    # Append mode ('a'): Creates new file, appends if exists
    with open('example.txt', 'a') as f:
        f.write('\nAppended text')
    
    # Read mode ('r'): Raises error if file doesn't exist
    with open('example.txt', 'r') as f:
        content = f.read()
    
    # Exclusive creation ('x'): Raises error if file exists
    try:
        with open('new_file.txt', 'x') as f:
            f.write('New file content')
    except FileExistsError:
        print("File already exists")
```

### Encoding Handlers

```python
from typing import Optional, TextIO
import codecs

class EncodingHandler:
    """Handle different file encodings."""
    
    @staticmethod
    def read_with_fallback(
        filepath: str,
        encodings: List[str] = ['utf-8', 'ascii', 'iso-8859-1']
    ) -> Optional[str]:
        """
        Try reading file with different encodings.
        
        Args:
            filepath: Path to file
            encodings: List of encodings to try
            
        Returns:
            Optional[str]: File content if successful
        """
        for encoding in encodings:
            try:
                with codecs.open(filepath, 'r', encoding=encoding) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue
        return None
    
    @staticmethod
    def detect_encoding(filepath: str) -> Optional[str]:
        """
        Detect file encoding.
        
        Args:
            filepath: Path to file
            
        Returns:
            Optional[str]: Detected encoding
        """
        import chardet
        
        with open(filepath, 'rb') as f:
            raw_data = f.read()
        result = chardet.detect(raw_data)
        return result['encoding']
```

## Context Managers

### Custom File Context Manager

```python
from typing import Optional, TextIO
import os

class FileHandler:
    """Custom file handler with context management."""
    
    def __init__(
        self,
        filepath: str,
        mode: str = 'r',
        encoding: str = 'utf-8',
        backup: bool = False
    ) -> None:
        self.filepath = filepath
        self.mode = mode
        self.encoding = encoding
        self.backup = backup
        self.file: Optional[TextIO] = None
        self._backup_path: Optional[str] = None
    
    def __enter__(self) -> TextIO:
        """Set up file handling and create backup if needed."""
        if self.backup and 'w' in self.mode:
            self._create_backup()
        
        self.file = open(
            self.filepath,
            self.mode,
            encoding=self.encoding
        )
        return self.file
    
    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        """Clean up file handling and restore from backup if needed."""
        if self.file:
            self.file.close()
        
        if exc_type and self.backup and self._backup_path:
            self._restore_backup()
    
    def _create_backup(self) -> None:
        """Create backup of existing file."""
        if os.path.exists(self.filepath):
            self._backup_path = f"{self.filepath}.bak"
            with open(self.filepath, 'r', encoding=self.encoding) as src:
                with open(self._backup_path, 'w', encoding=self.encoding) as dst:
                    dst.write(src.read())
    
    def _restore_backup(self) -> None:
        """Restore file from backup."""
        if self._backup_path and os.path.exists(self._backup_path):
            os.replace(self._backup_path, self.filepath)
```

## Binary Files

### Binary File Operations

```python
from typing import BinaryIO, Optional
import struct

class BinaryFileHandler:
    """Handle binary file operations."""
    
    @staticmethod
    def write_integers(
        filepath: str,
        numbers: List[int],
        byte_order: str = 'little'
    ) -> None:
        """
        Write integers to binary file.
        
        Args:
            filepath: Path to file
            numbers: List of integers
            byte_order: Byte order ('little' or 'big')
        """
        with open(filepath, 'wb') as f:
            for num in numbers:
                f.write(num.to_bytes(4, byte_order))
    
    @staticmethod
    def read_integers(
        filepath: str,
        count: Optional[int] = None,
        byte_order: str = 'little'
    ) -> List[int]:
        """
        Read integers from binary file.
        
        Args:
            filepath: Path to file
            count: Number of integers to read
            byte_order: Byte order ('little' or 'big')
            
        Returns:
            List[int]: List of integers
        """
        numbers = []
        with open(filepath, 'rb') as f:
            while True:
                if count and len(numbers) >= count:
                    break
                
                data = f.read(4)
                if not data:
                    break
                
                numbers.append(int.from_bytes(data, byte_order))
        return numbers
```

### Structured Binary Data

```python
import struct
from typing import Tuple, List

class StructuredBinaryHandler:
    """Handle structured binary data."""
    
    @staticmethod
    def write_record(
        file: BinaryIO,
        name: str,
        age: int,
        height: float
    ) -> None:
        """
        Write structured record to binary file.
        
        Args:
            file: Binary file object
            name: Person's name
            age: Person's age
            height: Person's height
        """
        name_bytes = name.encode('utf-8')
        name_length = len(name_bytes)
        
        # Format: <H (2-byte length) + name + I (4-byte age) + f (4-byte float)
        record_format = f'<H{name_length}sIf'
        record = struct.pack(
            record_format,
            name_length,
            name_bytes,
            age,
            height
        )
        file.write(record)
    
    @staticmethod
    def read_record(file: BinaryIO) -> Optional[Tuple[str, int, float]]:
        """
        Read structured record from binary file.
        
        Args:
            file: Binary file object
            
        Returns:
            Optional[Tuple[str, int, float]]: Record data if available
        """
        # Read name length
        length_data = file.read(2)
        if not length_data:
            return None
        
        name_length = struct.unpack('<H', length_data)[0]
        
        # Read name
        name_data = file.read(name_length)
        if not name_data:
            return None
        
        # Read age and height
        number_data = file.read(8)
        if not number_data:
            return None
        
        name = name_data.decode('utf-8')
        age, height = struct.unpack('<If', number_data)
        
        return name, age, height
```

## CSV and JSON

### CSV Operations

```python
import csv
from typing import List, Dict, Any
from pathlib import Path

class CSVHandler:
    """Handle CSV file operations."""
    
    @staticmethod
    def write_dict_rows(
        filepath: str,
        rows: List[Dict[str, Any]],
        fieldnames: Optional[List[str]] = None
    ) -> None:
        """
        Write dictionary rows to CSV.
        
        Args:
            filepath: Path to file
            rows: List of dictionaries
            fieldnames: List of field names
        """
        if not fieldnames and rows:
            fieldnames = list(rows[0].keys())
        
        with open(filepath, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(rows)
    
    @staticmethod
    def read_dict_rows(
        filepath: str,
        fieldnames: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        Read dictionary rows from CSV.
        
        Args:
            filepath: Path to file
            fieldnames: List of field names
            
        Returns:
            List[Dict[str, Any]]: List of dictionaries
        """
        with open(filepath, 'r', newline='') as f:
            if fieldnames:
                reader = csv.DictReader(f, fieldnames=fieldnames)
            else:
                reader = csv.DictReader(f)
            return list(reader)
```

### JSON Operations

```python
import json
from typing import Any, Optional
from pathlib import Path

class JSONHandler:
    """Handle JSON file operations."""
    
    @staticmethod
    def write_json(
        filepath: str,
        data: Any,
        indent: int = 4,
        ensure_ascii: bool = False
    ) -> None:
        """
        Write data to JSON file.
        
        Args:
            filepath: Path to file
            data: Data to write
            indent: Indentation level
            ensure_ascii: Whether to escape non-ASCII characters
        """
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(
                data,
                f,
                indent=indent,
                ensure_ascii=ensure_ascii
            )
    
    @staticmethod
    def read_json(filepath: str) -> Any:
        """
        Read data from JSON file.
        
        Args:
            filepath: Path to file
            
        Returns:
            Any: Parsed JSON data
        """
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    @staticmethod
    def update_json(
        filepath: str,
        updates: Dict[str, Any],
        create: bool = True
    ) -> None:
        """
        Update existing JSON file.
        
        Args:
            filepath: Path to file
            updates: Dictionary of updates
            create: Whether to create file if it doesn't exist
        """
        try:
            data = JSONHandler.read_json(filepath)
        except FileNotFoundError:
            if create:
                data = {}
            else:
                raise
        
        if isinstance(data, dict):
            data.update(updates)
            JSONHandler.write_json(filepath, data)
        else:
            raise TypeError("JSON root must be an object")
```

## Serialization

### Pickle Operations

```python
import pickle
from typing import Any, Optional
import os

class PickleHandler:
    """Handle pickle serialization."""
    
    @staticmethod
    def save_object(
        obj: Any,
        filepath: str,
        protocol: Optional[int] = None
    ) -> None:
        """
        Save object to pickle file.
        
        Args:
            obj: Object to save
            filepath: Path to file
            protocol: Pickle protocol version
        """
        with open(filepath, 'wb') as f:
            pickle.dump(obj, f, protocol=protocol)
    
    @staticmethod
    def load_object(filepath: str) -> Any:
        """
        Load object from pickle file.
        
        Args:
            filepath: Path to file
            
        Returns:
            Any: Loaded object
        """
        with open(filepath, 'rb') as f:
            return pickle.load(f)
    
    @staticmethod
    def safe_load(
        filepath: str,
        allowed_classes: Optional[List[type]] = None
    ) -> Any:
        """
        Safely load pickle file with restricted classes.
        
        Args:
            filepath: Path to file
            allowed_classes: List of allowed classes
            
        Returns:
            Any: Loaded object
        """
        class RestrictedUnpickler(pickle.Unpickler):
            def find_class(self, module, name):
                if allowed_classes:
                    for cls in allowed_classes:
                        if f"{module}.{name}" == f"{cls.__module__}.{cls.__name__}":
                            return cls
                raise pickle.UnpicklingError(
                    f"Class {module}.{name} is not allowed"
                )
        
        with open(filepath, 'rb') as f:
            return RestrictedUnpickler(f).load()
```

## Path Operations

### Path Management

```python
from pathlib import Path
from typing import Optional, Iterator
import shutil

class PathManager:
    """Manage file system paths."""
    
    @staticmethod
    def ensure_directory(path: str) -> Path:
        """
        Ensure directory exists.
        
        Args:
            path: Directory path
            
        Returns:
            Path: Path object
        """
        path_obj = Path(path)
        path_obj.mkdir(parents=True, exist_ok=True)
        return path_obj
    
    @staticmethod
    def find_files(
        directory: str,
        pattern: str = "*",
        recursive: bool = True
    ) -> Iterator[Path]:
        """
        Find files matching pattern.
        
        Args:
            directory: Directory to search
            pattern: Glob pattern
            recursive: Whether to search recursively
            
        Returns:
            Iterator[Path]: Matching file paths
        """
        path_obj = Path(directory)
        if recursive:
            return path_obj.rglob(pattern)
        return path_obj.glob(pattern)
    
    @staticmethod
    def safe_delete(path: str) -> None:
        """
        Safely delete file or directory.
        
        Args:
            path: Path to delete
        """
        path_obj = Path(path)
        try:
            if path_obj.is_file():
                path_obj.unlink()
            elif path_obj.is_dir():
                shutil.rmtree(path_obj)
        except Exception as e:
            print(f"Error deleting {path}: {e}")
```

## Advanced I/O

### Memory-Mapped Files

```python
import mmap
from typing import Optional
import os

class MemoryMappedFile:
    """Handle memory-mapped file operations."""
    
    def __init__(self, filepath: str) -> None:
        self.filepath = filepath
        self.file = None
        self.mm = None
    
    def __enter__(self) -> 'mmap.mmap':
        """Set up memory mapping."""
        self.file = open(self.filepath, 'r+b')
        self.mm = mmap.mmap(
            self.file.fileno(),
            0,
            access=mmap.ACCESS_WRITE
        )
        return self.mm
    
    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        """Clean up memory mapping."""
        if self.mm:
            self.mm.close()
        if self.file:
            self.file.close()

# Usage
def process_large_file(filepath: str) -> None:
    """Process large file using memory mapping."""
    with MemoryMappedFile(filepath) as mm:
        # Read content
        content = mm.read().decode('utf-8')
        
        # Modify content
        modified = content.replace('old', 'new')
        
        # Write back
        mm.seek(0)
        mm.write(modified.encode('utf-8'))
        mm.flush()
```

### Asynchronous I/O

```python
import asyncio
import aiofiles
from typing import List

class AsyncFileHandler:
    """Handle asynchronous file operations."""
    
    @staticmethod
    async def read_file(filepath: str) -> str:
        """
        Read file asynchronously.
        
        Args:
            filepath: Path to file
            
        Returns:
            str: File content
        """
        async with aiofiles.open(filepath, 'r') as f:
            return await f.read()
    
    @staticmethod
    async def write_file(filepath: str, content: str) -> None:
        """
        Write file asynchronously.
        
        Args:
            filepath: Path to file
            content: Content to write
        """
        async with aiofiles.open(filepath, 'w') as f:
            await f.write(content)
    
    @staticmethod
    async def process_files(filepaths: List[str]) -> List[str]:
        """
        Process multiple files concurrently.
        
        Args:
            filepaths: List of file paths
            
        Returns:
            List[str]: List of file contents
        """
        tasks = [
            AsyncFileHandler.read_file(filepath)
            for filepath in filepaths
        ]
        return await asyncio.gather(*tasks)
```

This enhanced version of File Handling and I/O Operations provides comprehensive coverage of Python's file handling and I/O features, with practical examples and modern best practices. The content is organized for both learning and reference, with a focus on type hints, context managers, and efficient I/O patterns.
